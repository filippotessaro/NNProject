{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Try_Majority.ipynb","version":"0.3.2","provenance":[{"file_id":"1XA8eQaMEWh72vKkQpKBhWfVUGwuHr9Wg","timestamp":1556454047199}],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"RX9FcAiACsIi","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O2bIwgloxYYw","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kOqgF-auD4NZ","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9CZ1IDlsEBil","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp \"gdrive/My Drive/datasets/output_immagini11_frames.zip\" dataset/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7PdZbpEZEGMB","colab_type":"code","colab":{}},"cell_type":"code","source":["!unzip dataset/output_immagini11_frames.zip"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"UvxtTYHlVfRK","colab":{}},"cell_type":"code","source":["# import necessary libraries\n","import torch\n","import torchvision\n","from torchvision import transforms as T\n","import torch.nn.functional as F\n","\n","# Library needed for visualization purposes\n","from tensorboardcolab import TensorBoardColab\n","\n","# Instantiate visualizer\n","tb = TensorBoardColab(graph_path='./log')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"dMC_LDYdWkI7","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","\n","class VGG(nn.Module):\n","    def __init__(self):\n","        super(VGG, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","         \n","            nn.MaxPool2d(2, 2, 1),\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","            nn.Conv2d(256, 256, 3, 1, 1),\n","\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.Conv2d(256, 512, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KJlHn-F-SiR6","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","\n","class VGG2(nn.Module):\n","    def __init__(self):\n","        super(VGG2, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 512, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.ReLU(),\n","            \n","            nn.Conv2d(512, 256, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.Conv2d(256, 128, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.Dropout(0.3),\n","            \n","            nn.Conv2d(128, 64, 3, 1, 1),\n","            nn.Conv2d(64, 8, 3, 1, 1),\n","            nn.MaxPool2d(2, 2, 1),\n","            nn.ReLU()\n","\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fb4pNi7NTd7d","colab_type":"code","colab":{}},"cell_type":"code","source":["class Dense_Block(nn.Module):\n","    def __init__(self, in_channels):\n","        super(Dense_Block, self).__init__()\n","        self.relu = nn.ReLU(inplace = True)\n","        self.bn = nn.BatchNorm2d(num_features = in_channels)\n","\n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv4 = nn.Conv2d(in_channels = 96, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv5 = nn.Conv2d(in_channels = 128, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n","    def forward(self, x):\n","        bn = self.bn(x) \n","        conv1 = self.relu(self.conv1(bn))\n","        conv2 = self.relu(self.conv2(conv1))\n","        # Concatenate in channel dimension\n","        c2_dense = self.relu(torch.cat([conv1, conv2], 1))\n","        conv3 = self.relu(self.conv3(c2_dense))\n","        c3_dense = self.relu(torch.cat([conv1, conv2, conv3], 1))\n","        conv4 = self.relu(self.conv4(c3_dense)) \n","        c4_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4], 1))\n","        conv5 = self.relu(self.conv5(c4_dense))\n","        c5_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4, conv5], 1))\n","        return c5_dense\n","\n","class Transition_Layer(nn.Module): \n","    def __init__(self, in_channels, out_channels):\n","        super(Transition_Layer, self).__init__() \n","\n","        self.relu = nn.ReLU(inplace = True) \n","        self.bn = nn.BatchNorm2d(num_features = out_channels) \n","        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, bias = False) \n","        self.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2, padding = 0) \n","    def forward(self, x): \n","        bn = self.bn(self.relu(self.conv(x))) \n","        out = self.avg_pool(bn) \n","        return out \n","    \n","class DenseNet(nn.Module): \n","    def __init__(self, nr_classes): \n","        super(DenseNet, self).__init__() \n","\n","        self.lowconv = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, padding = 3, bias = False) \n","        self.relu = nn.ReLU()\n","\n","        # Make Dense Blocks \n","        self.denseblock1 = self._make_dense_block(Dense_Block, 64) \n","        self.denseblock2 = self._make_dense_block(Dense_Block, 128)\n","        self.denseblock3 = self._make_dense_block(Dense_Block, 64)\n","        # Make transition Layers \n","        self.transitionLayer1 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 128) \n","        self.transitionLayer2 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 64) \n","        self.transitionLayer3 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 64)\n","        # Classifier \n","        self.bn = nn.BatchNorm2d(num_features = 64) \n","        self.pre_classifier = nn.Linear(64*8*8, 128) \n","        self.classifier = nn.Linear(128, nr_classes)\n"," \n","    def _make_dense_block(self, block, in_channels): \n","        layers = [] \n","        layers.append(block(in_channels)) \n","        return nn.Sequential(*layers) \n","    def _make_transition_layer(self, layer, in_channels, out_channels): \n","        modules = [] \n","        modules.append(layer(in_channels, out_channels)) \n","        return nn.Sequential(*modules) \n","    def forward(self, x): \n","        out = self.relu(self.lowconv(x)) \n","        #print('OUT 1', out.shape)\n","\n","        out = self.denseblock1(out) \n","        #print('OUT 2', out.shape)\n","\n","        out = self.transitionLayer1(out)\n","        #print('OUT 3', out.shape)\n","\n","        out = self.denseblock2(out)\n","        #print('OUT 4', out.shape)\n","\n","        out = self.transitionLayer2(out) \n","        #print('OUT 5', out.shape)\n","\n","\n","        out = self.denseblock3(out) \n","        #print('OUT 6', out.shape)\n","\n","        out = self.transitionLayer3(out)\n","        #print('OUT 7', out.shape)\n","\n","\n","        out = self.bn(out)\n","        #print('out 8', out.shape)\n","        out = out.view(-1, 64*8*8) \n","        #print('out 8', out.shape)\n","\n","\n","        out = self.pre_classifier(out) \n","        out = self.classifier(out)\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rm02Zp4o9Mc4","colab_type":"code","colab":{}},"cell_type":"code","source":["class BatchNorm(nn.Module):\n","    def __init__(self):\n","        super(BatchNorm, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20,\n","                               kernel_size=5,\n","                               stride=1)\n","        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n","        self.conv2_bn = nn.BatchNorm2d(50)\n","        self.dense1 = nn.Linear(in_features=50*61*61, out_features=64)\n","        self.dense1_bn = nn.BatchNorm1d(64)\n","        #self.dense2 = nn.Linear(64, 32)\n","        self.dense3 = nn.Linear(64, 8)\n","\n","\n","    def forward(self, x):\n","        #print(x.shape)\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        #print('1:',x.shape)\n","\n","        x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2))\n","        #print('2:',x.shape)\n","\n","        x = x.view(-1, 50*61*61) #reshape\n","        #print('3:',x.shape)\n","\n","        x = F.relu(self.dense1_bn(self.dense1(x)))\n","        #print('4:',x.shape)\n","\n","        #x = F.relu(self.dense2(x))\n","        x = F.relu(self.dense3(x))\n","        return F.log_softmax(x)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"gChf6TvWonrV"},"cell_type":"markdown","source":["### Define cost function"]},{"metadata":{"colab_type":"code","id":"6j5UrBH3oek8","colab":{}},"cell_type":"code","source":["def get_cost_function():\n","    use_gpu = torch.cuda.is_available()\n","    #cost_function = torch.nn.CrossEntropyLoss()\n","    cost_function = nn.CrossEntropyLoss().cuda() if use_gpu else nn.CrossEntropyLoss()\n","    return cost_function"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"U2TjXeVdorV9"},"cell_type":"markdown","source":["### Define the optimizer"]},{"metadata":{"colab_type":"code","id":"hBZN-WPboulR","colab":{}},"cell_type":"code","source":["def get_optimizer(net, lr, momentum):\n","    #optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n","    #optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=wd, amsgrad=False)\n","    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, nesterov = False)\n","    return optimizer\n","  \n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"wTkfrV64oxIL"},"cell_type":"markdown","source":["### Train and test functions"]},{"metadata":{"colab_type":"code","id":"t-sE5vFio0lf","colab":{}},"cell_type":"code","source":["def test(net, data_loader, cost_function, device='cuda:0'):\n","    samples = 0.\n","    cumulative_loss = 0.\n","\n","    cumulative_accuracy = 0.\n","\n","    net.eval() # Strictly needed if network contains layers which has different behaviours between train and tes\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets,path) in enumerate(data_loader):\n","            # Load data into GPU\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            # Forward pass\n","            outputs = net(inputs)\n","\n","            # Apply the loss\n","            loss = cost_function(outputs, targets)\n","\n","            # Better print something\n","            samples+=inputs.shape[0]\n","            cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","            _, predicted = outputs.max(1)\n","            cumulative_accuracy += predicted.eq(targets).sum().item()\n","\n","    return cumulative_loss/samples, cumulative_accuracy/samples*100\n","\n","\n","def train(net,data_loader,optimizer,cost_function, device='cuda:0'):\n","    samples = 0.\n","    cumulative_loss = 0.\n","    cumulative_accuracy = 0.\n","    net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n","    for batch_idx, (inputs, targets,path) in enumerate(data_loader):\n","        # Load data into GPU\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","      \n","        # Forward pass\n","        outputs = net(inputs)\n","\n","        # Apply the loss\n","        loss = cost_function(outputs,targets)\n","\n","        # Reset the optimizer\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update parameters\n","        optimizer.step()\n","\n","        optimizer.zero_grad()\n","\n","        # Better print something, no?\n","        samples+=inputs.shape[0]\n","        cumulative_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        cumulative_accuracy += predicted.eq(targets).sum().item()\n","\n","    return cumulative_loss/samples, cumulative_accuracy/samples*100"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UKniwFwWRaj9","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torchvision import datasets\n","\n","class ImageFolderWithPaths(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # the image file path\n","        path = self.imgs[index][0]\n","        # make a new tuple that includes original and the path\n","        tuple_with_path = (original_tuple + (path,))\n","        return tuple_with_path\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"qDxpo6uVo_8k","colab":{}},"cell_type":"code","source":["def get_data(batch_size, test_batch_size=64):\n","  \n","  # Prepare data transformations and then combine them sequentially\n","    transform = list()\n","    #transform.append(T.Grayscale(num_output_channels=1))\n","    #transform.append(T.Scale((128)))\n","    transform.append(T.ToTensor())  \n","    #transform.append(T.Normalize([0.485, 0.456, 0.406],\n","                                # [0.229, 0.224, 0.225]))      # Normalizes the Tensors between [-1, 1]\n","    transform = T.Compose(transform)                          # Composes the above transformations into one.\n","\n","    # Load data\n","    print('Start-Loading-Transform')\n","    #imagenet_data = torchvision.datasets.ImageFolder('./output_immagini11_frames/', transform=transform)\n","    imagenet_data = ImageFolderWithPaths('./output_immagini11_frames/', transform=transform)\n","    print('Finish transform')\n","    \n","    # Create train and test splits\n","    # We will create a 80:20 % train:test split\n","    num_samples = len(imagenet_data)\n","    training_samples = int(num_samples*0.7+1)\n","    test_samples = num_samples - training_samples\n","\n","    training_data, test_data = torch.utils.data.random_split(imagenet_data, [training_samples, test_samples])\n","    \n","    num_samples = training_samples\n","    training_samples = int(num_samples*0.5+1)\n","    validation_samples = num_samples - training_samples\n","    \n","    training_data, validation_data = torch.utils.data.random_split(training_data, [training_samples, validation_samples])    \n"," \n","    #name_train = list()\n","    #for name in training_data:\n","    #  name_train.append(name[2])\n","    #name_val = list()\n","    #for name in validation_data:\n","    #  name_val.append(name[2])\n","    #name_test = list()\n","    #for name in test_data:\n","    #  name_test.append(name[2])\n","    \n","    # Initialize dataloaders\n","    train_loader = torch.utils.data.DataLoader(training_data, batch_size = batch_size, shuffle = True)\n","    val_loader = torch.utils.data.DataLoader(validation_data, batch_size = batch_size, shuffle = False)\n","    test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n","\n","    return train_loader, val_loader, test_loader#, name_train, name_val, name_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dTK84hByD_vR","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torchvision.models as models\n","\n","\n","device='cuda:0'\n","#params\n","batch_size = 32\n","momentum = 0.9\n","learning_rate = 0.001\n","nr_classes = 8\n","num_epochs = 10\n","\n","train_loader, val_loader, test_loader = get_data(batch_size)\n","\n","#net = VGG().to(device)\n","\n","# GPU flag\n","use_gpu = torch.cuda.is_available()\n","densenet = DenseNet(nr_classes)\n","#densenet = BatchNorm()\n","if use_gpu:\n","  densenet.cuda()\n","\n","optimizer = get_optimizer(densenet, learning_rate, momentum)\n","cost_function = get_cost_function()\n","\n","\n","\n","print('Before training:')\n","train_loss, train_accuracy = test(densenet, train_loader, cost_function)\n","val_loss, val_accuracy = test(densenet, val_loader, cost_function)\n","test_loss, test_accuracy = test(densenet, test_loader, cost_function)\n","\n","print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n","print('-----------------------------------------------------')\n","\n","for e in range(num_epochs):\n","  train_loss, train_accuracy = train(densenet, train_loader, optimizer, cost_function)\n","  val_loss, val_accuracy = test(densenet, val_loader, cost_function)\n","  print('Epoch: {:d}'.format(e+1))\n","  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","  print('-----------------------------------------------------')\n","\n","print('After training:')\n","train_loss, train_accuracy = test(densenet, train_loader, cost_function)\n","val_loss, val_accuracy = test(densenet, val_loader, cost_function)\n","test_loss, test_accuracy = test(densenet, test_loader, cost_function)\n","\n","print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n","print('-----------------------------------------------------')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZR1eTG--sHgE","colab_type":"code","colab":{}},"cell_type":"code","source":["test_loader_copy = test_loader\n","val_loader_copy = val_loader\n","train_loader_copy = train_loader\n","densenet_copy = densenet\n","samples = 0.\n","cumulative_loss = 0.\n","cumulative_accuracy = 0.\n","\n","densenet_copy.eval() # Strictly needed if network contains layers which has different behaviours between train and tes\n","predicted_label = list()\n","real_label = list()\n","imgPath = list()\n","with torch.no_grad():\n","    for batch_idx, (inputs, targets,path) in enumerate(test_loader):\n","        # Load data into GPU\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        # Forward pass\n","        outputs = densenet_copy(inputs)\n","\n","        # Apply the loss\n","        loss = cost_function(outputs, targets)\n","\n","        # Better print something\n","        samples+=inputs.shape[0]\n","        cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","        _, predicted = outputs.max(1)\n","        predicted_label.extend(predicted.tolist())\n","        real_label.extend(targets.tolist())\n","        imgPath.append(path)\n","        cumulative_accuracy += predicted.eq(targets).sum().item()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"58smsgr3OKi7","colab_type":"code","colab":{}},"cell_type":"code","source":["imgPath[0][1][48:55]\n","C = list()\n","for i in imgPath:\n","  for j in i:\n","    C.append(j[29:49])\n","\n","UniqueC = set(C)\n","#print(UniqueC)\n","ind = list()\n","for idx in UniqueC:\n","  index = [i for i, s in enumerate(C) if idx in s]\n","#  print(index)\n","  ind.append(index)\n","  \n","  \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"bbVQrcf81aXO","colab_type":"code","colab":{}},"cell_type":"code","source":["from collections import Counter\n","\n","def get_first_mode(a):\n","    c = Counter(a)  \n","    mode_count = max(c.values())\n","    mode = {key for key, count in c.items() if count == mode_count}\n","    first_mode = next(x for x in a if x in mode)\n","    return first_mode"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f8EXIWUJwY1e","colab_type":"code","colab":{}},"cell_type":"code","source":["import statistics\n","from operator import itemgetter \n","final_label = list()\n","final_real_label = list()\n","#real_im_label = list()\n","for i in ind:\n","  #print(itemgetter(*i)(real_label))\n","  #print(itemgetter(*i)(predicted_label))\n","  predicted = itemgetter(*i)(predicted_label)\n","  real_im_label = itemgetter(*i)(real_label)\n","  #print(get_first_mode(predicted))\n","  final_label.append(get_first_mode(predicted))\n","  final_real_label.append(real_im_label[0])\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hrRuYCgb2M7e","colab_type":"code","colab":{}},"cell_type":"code","source":["final_real_label == final_label\n","acc = 0\n","l = len(final_label)\n","for i in range(0,l):\n","  if final_real_label[i] == final_label[i]:\n","    acc = acc + 1\n","    \n","final_acc = acc/len(UniqueC)\n","print('\\t Final Accuracy {:.2f}'.format(final_acc))"],"execution_count":0,"outputs":[]}]}